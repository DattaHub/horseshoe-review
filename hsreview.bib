@book{hastie09,
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  edition = {2nd},
  publisher = {Springer, New York},
  timestamp = {2010-06-03T15:15:09.000+0200},
  title = {The elements of statistical learning: data mining, inference and prediction},
  url = {http://www-stat.stanford.edu/~tibs/ElemStatLearn/},
  year = 2009
}
@book{buhlmann2011statistics,
  title={Statistics for high-dimensional data},
  author={B{\"u}hlmann, Peter and van de Geer, Sara},
  year={2011},
  publisher={Springer-Verlag Berlin Heidelberg}
}
@article{johnstone2004needles,
  title={Needles and straw in haystacks: Empirical {B}ayes estimates of possibly sparse sequences},
  author={Johnstone, Iain M and Silverman, Bernard W},
  journal={Annals of Statistics},
  volume={32},
  pages={1594--1649},
  year={2004},
  publisher={JSTOR}
}
@book{efron2010large,
  title={Large-scale inference: empirical {B}ayes methods for estimation, testing, and prediction},
  author={Efron, Bradley},
  volume={1},
  year={2010},
  publisher={Cambridge University Press}
}
@article{efron2008microarrays,
  title={Microarrays, empirical {B}ayes and the two-groups model},
  author={Efron, Bradley},
  journal={Statistical Science},
  volume={23},
  number={1},
  pages={1--22},
  year={2008},
  publisher={Institute of Mathematical Statistics}
}
@article{bogdan2011asymptotic,
  title={Asymptotic {B}ayes-optimality under sparsity of some multiple testing procedures},
  author={Bogdan, Ma{\l}gorzata and Chakrabarti, Arijit and Frommlet, Florian and Ghosh, Jayanta K},
  journal={The Annals of Statistics},
  volume={39},
  number={3},
  pages={1551--1579},
  year={2011},
  publisher={Institute of Mathematical Statistics}
}
@article{carvalho2009handling,
  title={Handling sparsity via the horseshoe},
  author={Carvalho, C. M. and Polson, N. G. and Scott, J. G.},
  journal={Journal of Machine Learning Research W\&CP},
  volume={5},
  pages={73-80},
  year={2009}
}
@article{carvalho2010horseshoe,
  title={The horseshoe estimator for sparse signals},
  author={Carvalho, Carlos M and Polson, Nicholas G and Scott, James G},
  journal={Biometrika},
volume={97},
  pages={465--480},
  year={2010},
  publisher={Biometrika Trust}
}
@article{polson2010shrink,
  title={Shrink globally, act locally: sparse {B}ayesian regularization and prediction},
  author={Polson, Nicholas G and Scott, James G},
  journal={{B}ayesian Statistics},
  volume={9},
  pages={501--538},
  year={2010},
  publisher={Citeseer}
}
@article{polson2012half,
  title={On the half-{C}auchy prior for a global scale parameter},
  author={Polson, Nicholas G and Scott, James G},
  journal={{B}ayesian Analysis},
  volume={7},
  number={4},
  pages={887--902},
  year={2012},
  publisher={International Society for {B}ayesian Analysis}
}
@article{polson2015mixtures,
  title={Mixtures, envelopes and hierarchical duality},
  author={Polson, Nicholas G and Scott, James G},
  journal={Journal of the Royal Statistical Society. Series B},
  year={2016},
  volume={78},
  pages={701--727},
  publisher={Wiley Online Library}
}
@inproceedings{armagan2011generalized,
  title={Generalized beta mixtures of {G}aussians},
  author={Armagan, Artin and Clyde, Merlise and Dunson, David B},
  booktitle={Advances in Neural Information Processing Systems},
  pages={523--531},
  year={2011}
}
@article{armagan2013generalized,
  title={Generalized double {P}areto shrinkage},
  author={Armagan, Artin and Dunson, David B and Lee, Jaeyong},
  journal={Statistica Sinica},
  volume={23},
  number={1},
  pages={119--143},
  year={2013},
  publisher={NIH Public Access}
}

@article{griffin2005alternative,
 title={Inference with normal-gamma prior distributions in regression problems},
  author={Griffin, Jim E and Brown, Philip J},
  journal={{B}ayesian Analysis},
  volume={5},
  number={1},
  pages={171--188},
  year={2010},
  publisher={International Society for {B}ayesian Analysis}
}
@article{zhang2016high,
  title={High Dimensional Linear Regression via the R2-D2 Shrinkage Prior},
  author={Zhang, Yan and Reich, Brian J and Bondell, Howard D},
  journal={arXiv preprint arXiv:1609.00046},
  year={2016}
}
@article{castillo2012needles,
  title={Needles and straw in a haystack: Posterior concentration for possibly sparse sequences},
  author={Castillo, Isma{\"e}l and van der Vaart, Aad},
  journal={The Annals of Statistics},
  volume={40},
  number={4},
  pages={2069--2101},
  year={2012},
  publisher={Institute of Mathematical Statistics}
}
@article{castillo2015bayesian,
author = "Castillo, Ismail and Schmidt-Hieber, Johannes and van der Vaart, Aad",
doi = "10.1214/15-AOS1334",
fjournal = "The Annals of Statistics",
journal = "Ann. Statist.",
month = "10",
number = "5",
pages = "1986--2018",
publisher = "The Institute of Mathematical Statistics",
title = "{B}ayesian linear regression with sparse priors",
url = "http://dx.doi.org/10.1214/15-AOS1334",
volume = "43",
year = "2015"
}
@article{fan2001variable,
  title={Variable selection via nonconcave penalized likelihood and its oracle properties},
  author={Fan, Jianqing and Li, Runze},
  journal={Journal of the American statistical Association},
  volume={96},
  number={456},
  pages={1348--1360},
  year={2001},
  publisher={Taylor \& Francis}
}
@article{zhang2010nearly,
author = "Zhang, Cun-Hui",
journal = "The Annals of Statistics",
number = "2",
pages = "894--942",
publisher = "The Institute of Mathematical Statistics",
title = "Nearly unbiased variable selection under minimax concave penalty",
volume = "38",
year = "2010"
}

@article{mazumder2012,
  title={Sparse{N}et: Coordinate descent with nonconvex penalties},
  author={Mazumder, Rahul and Friedman, Jerome H and Hastie, Trevor},
  journal={Journal of the American Statistical Association},
  year={2012},
  volume={106},
  pages={1125--1138},
  publisher={Taylor \& Francis}
}
@article{george2000variable,
  title={The variable selection problem},
  author={George, Edward I},
  journal={Journal of the American Statistical Association},
  volume={95},
  number={452},
  pages={1304--1308},
  year={2000},
  publisher={Taylor \& Francis Group}
}
@article{George0000,
author = {George, EdwardI. and Foster, Dean P.}, 
title = {Calibration and empirical {B}ayes variable selection},
volume = {87}, 
number = {4}, 
pages = {731-747}, 
year = {2000}, 
doi = {10.1093/biomet/87.4.731}, 
URL = {http://biomet.oxfordjournals.org/content/87/4/731.abstract}, 
eprint = {http://biomet.oxfordjournals.org/content/87/4/731.full.pdf+html}, 
journal = {Biometrika} 
}
@article{george2006,
author = "George, Edward I. and Liang, Feng and Xu, Xinyi",
doi = "10.1214/009053606000000155",
fjournal = "The Annals of Statistics",
journal = "The Annals of Statistics",
month = "02",
number = "1",
pages = "78--91",
publisher = "The Institute of Mathematical Statistics",
title = "Improved minimax predictive densities under {K}ullback-{L}eibler loss",
url = "http://dx.doi.org/10.1214/009053606000000155",
volume = "34",
year = "2006"
}
@article{mitchell88,
    author = {Mitchell, T. J. and Beauchamp, J. J.},
    citeulike-article-id = {4746918},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/2290129},
    citeulike-linkout-1 = {http://www.jstor.org/stable/2290129},
    doi = {10.2307/2290129},
    issn = {01621459},
    journal = {Journal of the American Statistical Association},
    keywords = {{B}ayesian, graphical-models, lasso, variable-selection},
    month = dec,
    number = {404},
    pages = {1023--1032},
    posted-at = {2009-10-26 20:15:32},
    priority = {3},
    publisher = {American Statistical Association},
    title = {{{B}ayesian Variable Selection in Linear Regression}},
    url = {http://dx.doi.org/10.2307/2290129},
    volume = {83},
    year = {1988}
}
@article{ishwaran2005spike,
  title={Spike and slab variable selection: frequentist and Bayesian strategies},
  author={Ishwaran, Hemant and Rao, J Sunil},
  journal={Annals of Statistics},
  pages={730--773},
  year={2005},
  publisher={JSTOR}
}
@article{rovckova2016spike,
  title={The spike-and-slab lasso},
  author={Ro{\v{c}}kov{\'a}, Veronika and George, Edward I},
  journal={Journal of the American Statistical Association},
  number={just-accepted},
  year={2016},
  publisher={Taylor \& Francis}
}
@article{tibshirani96,
  added-at = {2009-04-04T18:01:35.000+0200},
  author = {Tibshirani, R.},
  biburl = {http://www.bibsonomy.org/bibtex/290e648276aa6cd3c601e7c0a54366233/dieudonnew},
  interhash = {334927808d42a9a6bf8eae717fed41b3},
  intrahash = {90e648276aa6cd3c601e7c0a54366233},
  journal = {Journal of the Royal Statistical Society. Series B},
  keywords = {imported},
  pages = {267-288},
  timestamp = {2009-04-04T18:01:35.000+0200},
  title = {Regression Shrinkage and Selection via the Lasso},
  volume = 58,
  year = 1996
}
@book{hastie2015statistical,
  title={Statistical learning with sparsity},
  author={Hastie, Trevor and Tibshirani, Robert and Wainwright, Martin},
  year={2015},
  publisher={CRC press}
}
@book{james2013introduction,
  title={An introduction to statistical learning},
  author={James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  volume={6},
  year={2013},
  publisher={Springer}
}
@article{hoerl70,
author = { Arthur E. Hoerl  and  Robert W.   Kennard },
title = {Ridge Regression: Biased Estimation for Nonorthogonal Problems},
journal = {Technometrics},
volume = {12},
number = {1},
pages = {55-67},
year = {1970},
doi = {10.1080/00401706.1970.10488634},
URL = {http://www.tandfonline.com/doi/abs/10.1080/00401706.1970.10488634},
}
@article{stephens2009bayesian,
  title={Bayesian statistical methods for genetic association studies},
  author={Stephens, Matthew and Balding, David J},
  journal={Nature Reviews Genetics},
  volume={10},
  number={10},
  pages={681--690},
  year={2009},
  publisher={Nature Publishing Group}
}

@article{natarajan95,
 author = {Natarajan, B. K.},
 title = {Sparse Approximate Solutions to Linear Systems},
 journal = {SIAM J. Comput.},
 issue_date = {April 1995},
 volume = {24},
 number = {2},
 year = {1995},
 pages = {227--234},
 numpages = {8},
 acmid = {207987},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
 keywords = {linear systems, sparse solutions},
} 
@book{boyd2004convex,
  title={Convex Optimization},
  author={Boyd, Stephen and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge University Press},
  address={Cambridge}
}
@article{breheny2011coordinate,
  title={Coordinate descent algorithms for nonconvex penalized regression, with applications to biological feature selection},
  author={Breheny, Patrick and Huang, Jian},
  journal={The Annals of Applied Statistics},
  volume={5},
  number={1},
  pages={232--253},
  year={2011},
  publisher={NIH Public Access}
}
@article{polson2010large,
  title={Large-scale simultaneous testing with hypergeometric inverted-beta priors},
  author={Polson, Nicholas G and Scott, James G},
  journal={arXiv preprint arXiv:1010.5223},
  year={2010},
  publisher={Citeseer}
}
@article{polson2015proximal,
  title={Proximal algorithms in statistics and machine learning},
  author={Polson, Nicholas G and Scott, James G and Willard, Brandon T},
  journal={Statistical Science},
  volume={30},
  number={4},
  pages={559--581},
  year={2015},
  publisher={Institute of Mathematical Statistics}
}
@article{strawderman2013hierarchical,
  title={Hierarchical Bayes, maximum a posteriori estimators, and minimax concave penalized likelihood estimation},
  author={Strawderman, Robert L and Wells, Martin T and Schifano, Elizabeth D},
  journal={Electronic Journal of Statistics},
  volume={7},
  pages={973--990},
  year={2013},
  publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}

@article{schifano2010majorization,
  title={Majorization-minimization algorithms for nonsmoothly penalized objective functions},
  author={Schifano, Elizabeth D and Strawderman, Robert L and Wells, Martin T},
  journal={Electronic Journal of Statistics},
  volume={4},
  pages={1258--1299},
  year={2010},
  publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}
@article{bhadra2015horseshoe+,
  title={The Horseshoe+ Estimator of Ultra-Sparse Signals},
  author={Bhadra, Anindya and Datta, Jyotishka and Polson, Nicholas G and Willard, Brandon},
  journal={Bayesian Analysis},
  year={2016},
  volume={to appear}
}
@article{bhadra2016prediction,
  title={Prediction risk for global-local shrinkage regression},
  author={Bhadra, Anindya and Datta, Jyotishka and Li, Yunfan and Polson, Nicholas G and Willard, Brandon},
  journal={arXiv preprint arXiv:1605.04796},
  year={2016}
}
@article{bhadra2015default,
  title={Default {B}ayesian Analysis with Global-Local Shrinkage Priors},
  author={Bhadra, Anindya and Datta, Jyotishka and Polson, Nicholas G and Willard, Brandon},
  journal={Biometrika},
  volume={to appear},
  year={2016}
}
@article{bhadra2016global,
  title={Global-Local Mixtures},
  author={Bhadra, Anindya and Datta, Jyotishka and Polson, Nicholas G and Willard, Brandon},
  journal={arXiv preprint arXiv:1604.07487},
  year={2016}
}
@article{bhadra2017horseshoe,
  title={Horseshoe Regularization for Feature Subset Selection},
  author={Bhadra, Anindya and Datta, Jyotishka and Polson, Nicholas G and Willard, Brandon},
  journal={arXiv preprint arXiv:1702.07400},
  year={2017}
}
@article{van2014horseshoe,
  title={The horseshoe estimator: Posterior concentration around nearly black vectors},
  author={van der Pas, SL and Kleijn, BJK and van der Vaart, AW},
  journal={Electronic Journal of Statistics},
volume={8},
pages={2585--2618},
  year={2014}
}
@article{van2015conditions,
  title={Conditions for Posterior Contraction in the Sparse Normal Means Problem},
  author={van der Pas, St{\'e}phanie and Salomond, Jean-Bernard and Schmidt-Hieber, Johannes},
  journal={Electronic Journal of Statistics},
  volume={10},
  pages={976--1000},
  year={2016}
}
@article{van2016many,
  title={How many needles in the haystack? Adaptive inference and uncertainty quantification for the horseshoe},
  author={van der Pas, St{\'e}phanie and Szab{\'o}, Botond and van der Vaart, Aad},
  journal={arXiv:1607.01892},
  year={2016}
}
@article{van2017adaptive,
  title={Adaptive posterior contraction rates for the horseshoe},
  author={van der Pas, St{\'e}phanie and Szab{\'o}, Botond and van der Vaart and Aad},
  journal={arXiv:1702.03698},
  year={2017}
}
@article{datta2013asymptotic,
  title={Asymptotic properties of {B}ayes risk for the horseshoe prior},
  author={Datta, Jyotishka and Ghosh, Jayanta K},
  journal={{B}ayesian Analysis},
  volume={8},
  number={1},
  pages={111--132},
  year={2013},
  publisher={International Society for {B}ayesian Analysis}
}
@article{datta2016bayesian,
  title={Bayesian inference on quasi-sparse count data},
  author={Datta, Jyotishka and Dunson, David B},
  journal={Biometrika},
  volume={103},
  number={4},
  pages={971--983},
  year={2016},
  publisher={Oxford University Press}
}
@article{donoho1992maximum,
  title={Maximum entropy and the nearly black object},
  author={Donoho, David L and Johnstone, Iain M and Hoch, Jeffrey C and Stern, Alan S},
  journal={Journal of the Royal Statistical Society. Series B},
  volume={54},
  pages={41--81},
  year={1992},
  publisher={JSTOR}
}
@article{donoho1994ideal,
  title={Ideal spatial adaptation by wavelet shrinkage},
  author={Donoho, David L and Johnstone, Iain M},
  journal={biometrika},
  pages={425--455},
  year={1994},
  publisher={JSTOR}
}
@article{bhattacharya2014dirichlet,
 author = {Bhattacharya, Anirban and Pati, Debdeep and Pillai, Natesh S. and Dunson, David B.},
title = {Dirichlet-{L}aplace priors for optimal shrinkage},
journal = {Journal of the American Statistical Association},
volume = {110},
number = {},
pages = {1479--1490},
year = {2015}
}
@article{ghosh2016asymptotic,
  title={Asymptotic Optimality of One-Group Shrinkage Priors in Sparse High-dimensional Problems},
  author={Ghosh, Prasenjit and Chakrabarti, Arijit and others},
  journal={Bayesian Analysis},
  year={2016},
  publisher={International Society for Bayesian Analysis}
}
@article{ghosh2016testing,
  title={Asymptotic properties of Bayes risk of a general class of shrinkage priors in multiple hypothesis testing under sparsity},
  author={Ghosh, Prasenjit and Tang, Xueying and Ghosh, Malay and Chakrabarti, Arijit and others},
  journal={Bayesian Analysis},
  volume={11},
  number={3},
  pages={753--796},
  year={2016},
  publisher={International Society for Bayesian Analysis}
}
@article{tiao1965bayesian,
  title={{B}ayesian analysis of random-effect models in the analysis of variance. I. Posterior distribution of variance-components},
  author={Tiao, George C and Tan, WY},
  journal={Biometrika},
  pages={37--53},
  year={1965},
  publisher={JSTOR}
}
@article{morris2011estimating,
  title={Estimating random effects via adjustment for density maximization},
  author={Morris, Carl and Tang, Ruoxi and others},
  journal={Statistical Science},
  volume={26},
  number={2},
  pages={271--287},
  year={2011},
  publisher={Institute of Mathematical Statistics}
}
@article{zou2005regularization,
  title={Regularization and variable selection via the elastic net},
  author={Zou, Hui and Hastie, Trevor},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={67},
  number={2},
  pages={301--320},
  year={2005},
  publisher={Wiley Online Library}
}
@article{andrews1974scale,
  title={Scale mixtures of normal distributions},
  author={Andrews, David F and Mallows, Colin L},
  journal={Journal of the Royal Statistical Society. Series B (Methodological)},
  pages={99--102},
  year={1974},
  publisher={JSTOR}
}
@article{piironen2016hyperprior,
  title={On the Hyperprior Choice for the Global Shrinkage Parameter in the Horseshoe Prior},
  author={Piironen, Juho and Vehtari, Aki},
  journal={arXiv preprint arXiv:1610.05559},
  year={2016}
}
@article{ghosal2000,
author = "Ghosal, Subhashis and Ghosh, Jayanta K. and van der Vaart, Aad W.",
doi = "10.1214/aos/1016218228",
fjournal = "The Annals of Statistics",
journal = "Ann. Statist.",
month = "04",
number = "2",
pages = "500--531",
publisher = "The Institute of Mathematical Statistics",
title = "Convergence rates of posterior distributions",
url = "http://dx.doi.org/10.1214/aos/1016218228",
volume = "28",
year = "2000"
}
@article{wang2013class,
  title={On a class of shrinkage priors for covariance matrix estimation},
  author={Wang, Hao and Pillai, Natesh S},
  journal={Journal of Computational and Graphical Statistics},
  volume={22},
  number={3},
  pages={689--707},
  year={2013},
  publisher={Taylor \& Francis Group}
}
@article{sabetsarvestani_sparse_2014,
	title = {Sparse {Estimation} with {Generalized} {Beta} {Mixture} and the {Horseshoe} {Prior}},
	url = {http://search.arxiv.org:8081/paper.jsp?r=1411.2405&qid=1478992712845ler_nCnN_47610269&qs=horseshoe},
	urldate = {2016-11-12},
	author = {Sabetsarvestani, Zahra and Amindavar, Hamidreza},
	month = nov,
	year = {2014}
}
@article{scott_parameter_2010,
	title = {Parameter expansion in local-shrinkage models},
	url = {http://arxiv.org/abs/1010.5265},
	urldate = {2015-06-13},
	journal = {arXiv preprint arXiv:1010.5265},
	author = {Scott, James G.},
	year = {2010},
	note = {bibtex: scott\_parameter\_2010},
	keywords = {MCMC, Normal scale mixtures, parameter expansion, sparsity}
}

@article{makalic_simple_2016,
	title = {A simple sampler for the horseshoe estimator},
	volume = {23},
	issn = {1070-9908, 1558-2361},
	url = {http://arxiv.org/abs/1508.03884},
	doi = {10.1109/LSP.2015.2503725},
	abstract = {In this note we derive a simple Bayesian sampler for linear regression with the horseshoe hierarchy. A new interpretation of the horseshoe model is presented, and extensions to logistic regression and alternative hierarchies, such as horseshoe\$+\$, are discussed. Due to the conjugacy of the proposed hierarchy, Chib's algorithm may be used to easily compute the marginal likelihood of the model.},
	number = {1},
	urldate = {2016-11-12},
	journal = {IEEE Signal Processing Letters},
	author = {Makalic, Enes and Schmidt, Daniel F.},
	month = jan,
	year = {2016},
	note = {arXiv: 1508.03884},
	keywords = {Statistics - Computation},
	pages = {179--182}
}

@article{terenin_gpu-accelerated_2016,
	title = {{GPU}-accelerated {Gibbs} {Sampling}},
	url = {http://arxiv.org/abs/1608.04329},
	abstract = {Gibbs sampling is a widely used Markov Chain Monte Carlo (MCMC) method for numerically approximating integrals of interest in Bayesian statistics and other mathematical sciences. Many implementations of MCMC methods do not extend easily to parallel computing environments, as their inherently sequential nature incurs a large synchronization cost. In this paper, we show how to do Gibbs sampling in a fully data-parallel manner on a graphics processing unit (GPU) for a large class of exchangeable models that admit latent variable representations. We demonstrate the scheme on a horseshoe probit regression model, and find that our implementation scales effectively to thousands of predictors and millions of data points simultaneously.},
	urldate = {2016-11-12},
	journal = {arXiv:1608.04329 [cs, stat]},
	author = {Terenin, Alexander and Dong, Shawfeng and Draper, David},
	month = aug,
	year = {2016},
	note = {arXiv: 1608.04329},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Statistics - Computation}
}

@misc{pas_horseshoe:_2016,
	title = {horseshoe: {Implementation} of the {Horseshoe} {Prior}},
	copyright = {GPL-3},
	shorttitle = {horseshoe},
	url = {https://cran.r-project.org/web/packages/horseshoe/index.html},
	abstract = {Contains functions for applying the horseshoe prior to high-
    dimensional linear regression, yielding the posterior mean and credible
    intervals, amongst other things. The key parameter tau can be equipped with
    a prior or estimated via maximum marginal likelihood estimation (MMLE).
    The main function, horseshoe, is for linear regression. In addition, there
    are functions specifically for the sparse normal means problem, allowing
    for faster computation of for example the posterior mean and posterior
    variance. Finally, there is a function available to perform variable
    selection, using either a form of thresholding, or credible intervals.},
	urldate = {2016-11-12},
	author = {Pas, Stephanie van der and Scott, James and Chakraborty, Antik and Bhattacharya, Anirban},
	month = nov,
	year = {2016}
}

@article{bhattacharya_fast_2015,
	title = {Fast sampling with {Gaussian} scale-mixture priors in high-dimensional regression},
	url = {http://arxiv.org/abs/1506.04778},
	abstract = {We propose an efficient way to sample from a class of structured multivariate Gaussian distributions which routinely arise as conditional posteriors of model parameters that are assigned a conditionally Gaussian prior. The proposed algorithm only requires matrix operations in the form of matrix multiplications and linear system solutions. We exhibit that the computational complexity of the proposed algorithm grows linearly with the dimension unlike existing algorithms relying on Cholesky factorizations with cubic orders of complexity. The algorithm should be broadly applicable in settings where Gaussian scale mixture priors are used on high dimensional model parameters. We provide an illustration through posterior sampling in a high dimensional regression setting with a horseshoe prior on the vector of regression coefficients.},
	urldate = {2016-06-17},
	journal = {arXiv:1506.04778 [stat]},
	author = {Bhattacharya, Anirban and Chakraborty, Antik and Mallick, Bani K.},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.04778},
	keywords = {Statistics - Computation}
}

@article{hahn_elliptical_2016,
	title = {Elliptical slice sampling for {Bayesian} shrinkage regression with applications to causal inference},
	url = {http://faculty.chicagobooth.edu/richard.hahn/JCGS_submit.pdf},
	urldate = {2016-09-02},
	author = {Hahn, P. Richard and He, Jingyu and Lopes, Hedibert},
	year = {2016},
	keywords = {horseshoe prior, sparsity}
}
@article{hans2011elastic,
  title={Elastic net regression modeling with the orthant normal prior},
  author={Hans, Chris},
  journal={Journal of the American Statistical Association},
  volume={106},
  number={496},
  pages={1383--1393},
  year={2011},
  publisher={Taylor \& Francis}
}
@article{tseng2001convergence,
  title={Convergence of a block coordinate descent method for nondifferentiable minimization},
  author={Tseng, Paul},
  journal={Journal of optimization theory and applications},
  volume={109},
  number={3},
  pages={475--494},
  year={2001},
  publisher={Springer}
}
@article{fu1998penalized,
  title={Penalized regressions: the bridge versus the lasso},
  author={Fu, Wenjiang J},
  journal={Journal of computational and graphical statistics},
  volume={7},
  number={3},
  pages={397--416},
  year={1998},
  publisher={Taylor \& Francis}
}
@article{friedman2007pathwise,
  title={Pathwise coordinate optimization},
  author={Friedman, Jerome and Hastie, Trevor and H{\"o}fling, Holger and Tibshirani, Robert and others},
  journal={The Annals of Applied Statistics},
  volume={1},
  number={2},
  pages={302--332},
  year={2007},
  publisher={Institute of Mathematical Statistics}
}
@article{tibshirani2014praise,
  title={In praise of sparsity and convexity},
  author={Tibshirani, Robert J},
  journal={Past, Present, and Future of Statistical Science},
  pages={497--505},
  year={2014},
  publisher={Citeseer}
}
@article{friedman2010regularization,
  title={Regularization paths for generalized linear models via coordinate descent},
  author={Friedman, Jerome and Hastie, Trevor and Tibshirani, Rob},
  journal={Journal of statistical software},
  volume={33},
  number={1},
  pages={1},
  year={2010},
  publisher={NIH Public Access}
}
@article{sabetsarvestani_sparse_2014,
	title = {Sparse {Estimation} with {Generalized} {Beta} {Mixture} and the {Horseshoe} {Prior}},
	url = {http://search.arxiv.org:8081/paper.jsp?r=1411.2405&qid=1478992712845ler_nCnN_47610269&qs=horseshoe},
	urldate = {2016-11-12},
	author = {Sabetsarvestani, Zahra and Amindavar, Hamidreza},
	month = nov,
	year = {2014}
}

@article{scott_parameter_2010,
	title = {Parameter expansion in local-shrinkage models},
	url = {http://arxiv.org/abs/1010.5265},
	urldate = {2015-06-13},
	journal = {arXiv preprint arXiv:1010.5265},
	author = {Scott, James G.},
	year = {2010},
	note = {bibtex: scott\_parameter\_2010},
	keywords = {MCMC, Normal scale mixtures, parameter expansion, sparsity}
}

@article{makalic_simple_2016,
	title = {A simple sampler for the horseshoe estimator},
	volume = {23},
	issn = {1070-9908, 1558-2361},
	url = {http://arxiv.org/abs/1508.03884},
	doi = {10.1109/LSP.2015.2503725},
	abstract = {In this note we derive a simple Bayesian sampler for linear regression with the horseshoe hierarchy. A new interpretation of the horseshoe model is presented, and extensions to logistic regression and alternative hierarchies, such as horseshoe\$+\$, are discussed. Due to the conjugacy of the proposed hierarchy, Chib's algorithm may be used to easily compute the marginal likelihood of the model.},
	number = {1},
	urldate = {2016-11-12},
	journal = {IEEE Signal Processing Letters},
	author = {Makalic, Enes and Schmidt, Daniel F.},
	month = jan,
	year = {2016},
	note = {arXiv: 1508.03884},
	keywords = {Statistics - Computation},
	pages = {179--182}
}

@article{terenin_gpu-accelerated_2016,
	title = {{GPU}-accelerated {Gibbs} {Sampling}},
	url = {http://arxiv.org/abs/1608.04329},
	abstract = {Gibbs sampling is a widely used Markov Chain Monte Carlo (MCMC) method for numerically approximating integrals of interest in Bayesian statistics and other mathematical sciences. Many implementations of MCMC methods do not extend easily to parallel computing environments, as their inherently sequential nature incurs a large synchronization cost. In this paper, we show how to do Gibbs sampling in a fully data-parallel manner on a graphics processing unit (GPU) for a large class of exchangeable models that admit latent variable representations. We demonstrate the scheme on a horseshoe probit regression model, and find that our implementation scales effectively to thousands of predictors and millions of data points simultaneously.},
	urldate = {2016-11-12},
	journal = {arXiv:1608.04329 [cs, stat]},
	author = {Terenin, Alexander and Dong, Shawfeng and Draper, David},
	month = aug,
	year = {2016},
	note = {arXiv: 1608.04329},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Statistics - Computation}
}

@misc{pas_horseshoe:_2016,
	title = {horseshoe: {Implementation} of the {Horseshoe} {Prior}},
	copyright = {GPL-3},
	shorttitle = {horseshoe},
	url = {https://cran.r-project.org/web/packages/horseshoe/index.html},
	abstract = {Contains functions for applying the horseshoe prior to high-
    dimensional linear regression, yielding the posterior mean and credible
    intervals, amongst other things. The key parameter tau can be equipped with
    a prior or estimated via maximum marginal likelihood estimation (MMLE).
    The main function, horseshoe, is for linear regression. In addition, there
    are functions specifically for the sparse normal means problem, allowing
    for faster computation of for example the posterior mean and posterior
    variance. Finally, there is a function available to perform variable
    selection, using either a form of thresholding, or credible intervals.},
	urldate = {2016-11-12},
	author = {Pas, Stephanie van der and Scott, James and Chakraborty, Antik and Bhattacharya, Anirban},
	month = nov,
	year = {2016}
}

@article{bhattacharya_fast_2015,
	title = {Fast sampling with {Gaussian} scale-mixture priors in high-dimensional regression},
	url = {http://arxiv.org/abs/1506.04778},
	abstract = {We propose an efficient way to sample from a class of structured multivariate Gaussian distributions which routinely arise as conditional posteriors of model parameters that are assigned a conditionally Gaussian prior. The proposed algorithm only requires matrix operations in the form of matrix multiplications and linear system solutions. We exhibit that the computational complexity of the proposed algorithm grows linearly with the dimension unlike existing algorithms relying on Cholesky factorizations with cubic orders of complexity. The algorithm should be broadly applicable in settings where Gaussian scale mixture priors are used on high dimensional model parameters. We provide an illustration through posterior sampling in a high dimensional regression setting with a horseshoe prior on the vector of regression coefficients.},
	urldate = {2016-06-17},
	journal = {arXiv:1506.04778 [stat]},
	author = {Bhattacharya, Anirban and Chakraborty, Antik and Mallick, Bani K.},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.04778},
	keywords = {Statistics - Computation}
}

@article{hahn_elliptical_2016,
	title = {Elliptical slice sampling for {Bayesian} shrinkage regression with applications to causal inference},
	url = {http://faculty.chicagobooth.edu/richard.hahn/JCGS_submit.pdf},
	urldate = {2016-09-02},
	author = {Hahn, P. Richard and He, Jingyu and Lopes, Hedibert},
	year = {2016},
	keywords = {horseshoe prior, sparsity}
}
@article{tibshirani2005sparsity,
  title={Sparsity and smoothness via the fused lasso},
  author={Tibshirani, Robert and Saunders, Michael and Rosset, Saharon and Zhu, Ji and Knight, Keith},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={67},
  number={1},
  pages={91--108},
  year={2005},
  publisher={Wiley Online Library}
}
@article{zou2006adaptive,
  title={The adaptive lasso and its oracle properties},
  author={Zou, Hui},
  journal={Journal of the American statistical association},
  volume={101},
  number={476},
  pages={1418--1429},
  year={2006},
  publisher={Taylor \& Francis}
}
@article{donoho2006compressed,
  title={Compressed sensing},
  author={Donoho, David L},
  journal={IEEE Transactions on information theory},
  volume={52},
  number={4},
  pages={1289--1306},
  year={2006},
  publisher={IEEE}
}
@article{candes2008restricted,
  title={The restricted isometry property and its implications for compressed sensing},
  author={Candes, Emmanuel J},
  journal={Comptes Rendus Mathematique},
  volume={346},
  number={9-10},
  pages={589--592},
  year={2008},
  publisher={Elsevier}
}
@article{tibshirani2011solution,
  title={The solution path of the generalized lasso},
  author={Tibshirani, Ryan J and Taylor, Jonathan and others},
  journal={The Annals of Statistics},
  volume={39},
  number={3},
  pages={1335--1371},
  year={2011},
  publisher={Institute of Mathematical Statistics}
}
@article{friedman2008sparse,
  title={Sparse inverse covariance estimation with the graphical lasso},
  author={Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
  journal={Biostatistics},
  volume={9},
  number={3},
  pages={432--441},
  year={2008},
  publisher={Biometrika Trust}
}
@article{yuan2006model,
  title={Model selection and estimation in regression with grouped variables},
  author={Yuan, Ming and Lin, Yi},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={68},
  number={1},
  pages={49--67},
  year={2006},
  publisher={Wiley Online Library}
}
@article{bien2013lasso,
  title={A lasso for hierarchical interactions},
  author={Bien, Jacob and Taylor, Jonathan and Tibshirani, Robert},
  journal={Annals of statistics},
  volume={41},
  number={3},
  pages={1111},
  year={2013},
  publisher={NIH Public Access}
}
@article{mazumder2010spectral,
  title={Spectral regularization algorithms for learning large incomplete matrices},
  author={Mazumder, Rahul and Hastie, Trevor and Tibshirani, Robert},
  journal={Journal of machine learning research},
  volume={11},
  number={Aug},
  pages={2287--2322},
  year={2010}
}
@article{jolliffe2003modified,
  title={A modified principal component technique based on the LASSO},
  author={Jolliffe, Ian T and Trendafilov, Nickolay T and Uddin, Mudassir},
  journal={Journal of computational and Graphical Statistics},
  volume={12},
  number={3},
  pages={531--547},
  year={2003},
  publisher={Taylor \& Francis}
}
@article{witten2009penalized,
  title={A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis},
  author={Witten, Daniela M and Tibshirani, Robert and Hastie, Trevor},
  journal={Biostatistics},
  pages={kxp008},
  year={2009},
  publisher={Biometrika Trust}
}
@article{tibshirani2011nearly,
  title={Nearly-isotonic regression},
  author={Tibshirani, Ryan J and Hoefling, Holger and Tibshirani, Robert},
  journal={Technometrics},
  volume={53},
  number={1},
  pages={54--61},
  year={2011},
  publisher={Taylor \& Francis}
}
@article{belloni2011square,
  title={Square-root lasso: pivotal recovery of sparse signals via conic programming},
  author={Belloni, Alexandre and Chernozhukov, Victor and Wang, Lie},
  journal={Biometrika},
  volume={98},
  number={4},
  pages={791--806},
  year={2011},
  publisher={Biometrika Trust}
}
@article{sun2012scaled,
  title={Scaled sparse linear regression},
  author={Sun, Tingni and Zhang, Cun-Hui},
  journal={Biometrika},
  volume={99},
  number={4},
  pages={879--898},
  year={2012},
  publisher={Oxford University Press}
}
@article{candes2007dantzig,
  title={The Dantzig selector: Statistical estimation when p is much larger than n},
  author={Candes, Emmanuel and Tao, Terence},
  journal={The Annals of Statistics},
  pages={2313--2351},
  year={2007},
  publisher={IMS}
}
@article{candes2010power,
  title={The power of convex relaxation: Near-optimal matrix completion},
  author={Cand{\`e}s, Emmanuel J and Tao, Terence},
  journal={IEEE Transactions on Information Theory},
  volume={56},
  number={5},
  pages={2053--2080},
  year={2010},
  publisher={IEEE}
}
@inproceedings{peltola2014hierarchical,
  title={Hierarchical Bayesian survival analysis and projective covariate selection in cardiovascular event risk prediction},
  author={Peltola, Tomi and Havulinna, Aki S and Salomaa, Veikko and Vehtari, Aki},
  booktitle={Proceedings of the Eleventh UAI Conference on Bayesian Modeling Applications Workshop-Volume 1218},
  pages={79--88},
  year={2014},
  organization={CEUR-WS. org}
}